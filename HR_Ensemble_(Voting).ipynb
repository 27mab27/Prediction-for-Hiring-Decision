{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load dataset\n",
    "df = pd.read_csv('recruitment_data 2.csv')\n",
    "\n",
    "# Define the features and the target class\n",
    "x = df.drop(columns=['HiringDecision'], axis=1)\n",
    "y = df['HiringDecision']\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load the saved models\n",
    "model_paths = [\n",
    "    'best_svm_model.pkl',\n",
    "    'catBoost1model.pkl',\n",
    "    'best_knn_model.pkl',\n",
    "    'LR_model_imb.pkl',\n",
    "    'best_gnb_model.pkl',\n",
    "    'RFmodel.pkl',\n",
    "    'xgbimba.pkl',\n",
    "    'DTmodel89.pkl'\n",
    "]\n",
    "\n",
    "models = []\n",
    "for path in model_paths:\n",
    "    try:\n",
    "        model = joblib.load(path)\n",
    "        if hasattr(model, 'fit'):\n",
    "            models.append(model)\n",
    "        else:\n",
    "            print(f\"Error: Loaded object from {path} is not a valid model.\")\n",
    "    except ModuleNotFoundError as e:\n",
    "        print(f\"ModuleNotFoundError for {path}: {e}\")\n",
    "\n",
    "model_names = [f'model_{i+1}' for i in range(len(models))]\n",
    "estimators = list(zip(model_names, models))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Define possible voting schemes\n",
    "voting_schemes = ['hard', 'soft']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))]))): 91.33%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))]))): 94.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))]))): 89.33%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))]))): 94.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 90.67%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 94.67%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 96.00%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 96.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 96.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))]))): 88.44%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))]))): 87.56%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 89.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 87.56%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 90.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 92.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 90.00%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 91.33%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 88.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 89.78%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 89.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 88.44%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 89.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 91.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 89.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 91.78%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 88.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 90.44%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 91.78%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 89.78%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 91.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 89.33%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.44%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.67%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.00%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.56%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.56%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))]))): 90.44%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))]))): 94.89%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 91.56%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 95.56%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 96.00%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 96.44%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.67%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 96.00%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.11%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.67%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 90.44%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 94.89%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 96.22%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 96.22%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.33%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 96.22%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.67%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.11%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 95.78%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 96.22%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.11%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 96.22%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.11%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.56%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.78%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 96.22%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 96.22%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 96.00%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.33%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 96.00%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 88.44%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 87.11%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 90.22%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 91.11%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 89.33%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 91.56%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 88.44%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.00%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 91.78%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 92.00%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 90.22%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.00%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 88.67%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.67%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.00%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.44%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.44%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.67%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.00%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.22%\n",
      "Test Accuracy with voting=hard and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 90.44%\n",
      "Test Accuracy with voting=soft and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 91.56%\n",
      "Test Accuracy with voting=hard and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 89.78%\n",
      "Test Accuracy with voting=soft and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 91.78%\n",
      "Test Accuracy with voting=hard and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 89.11%\n",
      "Test Accuracy with voting=soft and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.67%\n",
      "Test Accuracy with voting=hard and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.44%\n",
      "Test Accuracy with voting=soft and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.67%\n",
      "Test Accuracy with voting=hard and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.78%\n",
      "Test Accuracy with voting=soft and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.33%\n",
      "Test Accuracy with voting=hard and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.89%\n",
      "Test Accuracy with voting=soft and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.11%\n",
      "Test Accuracy with voting=hard and models (('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.22%\n",
      "Test Accuracy with voting=soft and models (('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.67%\n",
      "Test Accuracy with voting=hard and models (('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.67%\n",
      "Test Accuracy with voting=soft and models (('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.11%\n",
      "Test Accuracy with voting=hard and models (('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.11%\n",
      "Test Accuracy with voting=soft and models (('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.78%\n",
      "Test Accuracy with voting=hard and models (('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.89%\n",
      "Test Accuracy with voting=soft and models (('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.44%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))]))): 90.22%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))]))): 92.67%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 90.67%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 94.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 93.33%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 96.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.44%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.67%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 90.22%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 93.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 92.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 95.33%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.22%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.67%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 92.67%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 95.56%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.22%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.56%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.33%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 96.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 96.00%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 88.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 88.44%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 90.00%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 90.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 90.00%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 90.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 88.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 89.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 90.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 91.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 90.22%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 91.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 88.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 89.56%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.44%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 93.33%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.44%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.44%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 90.22%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 90.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 89.56%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 90.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 89.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.44%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.00%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 93.56%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.00%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.78%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.33%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.33%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.44%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 90.44%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 94.00%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 92.89%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.00%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 96.00%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.67%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.67%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 92.89%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 95.56%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.22%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.56%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.89%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.33%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.11%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.78%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 92.44%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 95.56%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.00%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.56%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.56%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.89%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.11%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.67%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.89%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.33%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.44%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 96.22%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 90.67%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 91.11%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 90.00%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 90.89%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 88.44%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 89.11%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.22%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 93.78%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.67%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.44%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.00%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.67%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.22%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.22%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.78%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.89%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.44%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.33%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.56%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.00%\n",
      "Test Accuracy with voting=hard and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.00%\n",
      "Test Accuracy with voting=soft and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 93.78%\n",
      "Test Accuracy with voting=hard and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.78%\n",
      "Test Accuracy with voting=soft and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.11%\n",
      "Test Accuracy with voting=hard and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.11%\n",
      "Test Accuracy with voting=soft and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.56%\n",
      "Test Accuracy with voting=hard and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.44%\n",
      "Test Accuracy with voting=soft and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.00%\n",
      "Test Accuracy with voting=hard and models (('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.00%\n",
      "Test Accuracy with voting=soft and models (('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 89.56%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))]))): 92.67%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 91.33%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 94.67%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 91.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.67%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.22%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 92.22%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 95.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 91.56%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.33%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.67%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.33%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.00%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 90.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 94.44%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 90.44%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.22%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 89.78%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.44%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.67%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.56%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.22%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.33%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.67%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.56%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.33%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 96.22%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.44%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.56%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.33%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 89.33%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 90.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 89.33%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 90.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 89.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 89.56%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 90.67%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.67%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.44%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 89.78%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.22%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 91.56%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 93.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.22%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.44%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.33%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 90.22%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.44%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 89.56%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 89.56%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.44%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.33%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.56%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.00%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 92.00%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 94.89%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 91.33%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.89%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.67%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.67%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.11%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 96.00%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.22%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.11%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.56%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.33%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.11%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.33%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.56%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.22%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.56%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.11%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 96.00%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.89%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.11%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.22%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.56%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.56%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 96.00%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.56%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 96.00%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 91.56%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 93.11%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.67%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.56%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.00%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.22%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.11%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.00%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.00%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.22%\n",
      "Test Accuracy with voting=hard and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.00%\n",
      "Test Accuracy with voting=soft and models (('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 91.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123))): 93.78%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 90.67%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.00%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.67%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.67%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.78%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.44%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.56%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.22%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.11%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.44%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.44%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.00%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.33%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.56%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 90.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 91.56%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.00%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.89%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.00%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.33%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.56%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.56%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.44%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.56%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 91.78%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.33%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 92.67%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 95.33%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.89%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.11%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.22%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.89%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.89%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.56%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.89%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.67%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.78%\n",
      "Test Accuracy with voting=hard and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.44%\n",
      "Test Accuracy with voting=soft and models (('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.00%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 91.78%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...))): 94.67%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.22%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.67%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.44%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.22%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.89%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.44%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.33%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 90.67%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 93.11%\n",
      "Test Accuracy with voting=hard and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 94.67%\n",
      "Test Accuracy with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.11%\n",
      "Test Accuracy with voting=hard and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 92.44%\n",
      "Test Accuracy with voting=soft and models (('model_1', Pipeline(steps=[('selectkbest', SelectKBest(k=7)),\n",
      "                ('svc',\n",
      "                 SVC(C=0.1, gamma=1, kernel='linear', probability=True))])), ('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_4', Pipeline(steps=[('feature_selection', SelectKBest(k=8)),\n",
      "                ('logistic_regression',\n",
      "                 LogisticRegression(C=0.1, solver='liblinear'))])), ('model_5', Pipeline(steps=[('selectkbest', SelectKBest(k=6)),\n",
      "                ('gnb', GaussianNB(var_smoothing=5.336699231206313e-06))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)), ('model_7', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depg=7, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, ...)), ('model_8', Pipeline(steps=[('smote', SMOTE(random_state=123)),\n",
      "                ('select_k_best', SelectKBest(k=8)),\n",
      "                ('classifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=8,\n",
      "                                        min_samples_leaf=4,\n",
      "                                        min_samples_split=10,\n",
      "                                        random_state=123))]))): 95.11%\n",
      "Best Test Accuracy: 96.44% with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)))\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "best_combination = None\n",
    "best_voting_scheme = None\n",
    "best_score = 0\n",
    "\n",
    "# Iterate over all possible combinations of models with at least 3 models\n",
    "for L in range(3, len(estimators) + 1):\n",
    "    for subset in itertools.combinations(estimators, L):\n",
    "        # Iterate over all voting schemes\n",
    "        for voting in voting_schemes:\n",
    "            try:\n",
    "                voting_clf = VotingClassifier(\n",
    "                    estimators=list(subset),\n",
    "                    voting=voting\n",
    "                )\n",
    "                voting_clf.fit(x_train, y_train)\n",
    "                y_pred_test = voting_clf.predict(x_test)\n",
    "                test_accuracy = accuracy_score(y_test, y_pred_test) * 100\n",
    "\n",
    "                if test_accuracy > best_score:\n",
    "                    best_score = test_accuracy\n",
    "                    best_combination = subset\n",
    "                    best_voting_scheme = voting\n",
    "\n",
    "                print(f\"Test Accuracy with voting={voting} and models {subset}: {test_accuracy:.2f}%\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed with voting={voting} and models {subset}: {e}\")\n",
    "\n",
    "print(f\"Best Test Accuracy: {best_score:.2f}% with voting={best_voting_scheme} and models {best_combination}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Test Accuracy: 96.44% with voting=soft and models (('model_2', <catboost.core.CatBoostClassifier object at 0x149bbc380>), ('model_3', Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(metric='euclidean', n_neighbors=3))])), ('model_6', RandomForestClassifier(bootstrap=False, max_depth=50, min_samples_leaf=2,\n",
      "                       min_samples_split=5, n_estimators=500, random_state=123)))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Test Accuracy: {best_score:.2f}% with voting={best_voting_scheme} and models {best_combination}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  96.44444444444444\n",
      "Recall:  96.44444444444444\n",
      "Precision:  96.4291282051282\n",
      "F1-Score:  96.4274558559437\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.9512907821971068\n",
      "Loaded model accuracy: 96.44444444444444\n",
      "VotingClassifier(estimators=[('model_2',\n",
      "                              <catboost.core.CatBoostClassifier object at 0x14a387fb0>),\n",
      "                             ('model_3',\n",
      "                              Pipeline(steps=[('selectkbest', SelectKBest(k=1)),\n",
      "                                              ('knn',\n",
      "                                               KNeighborsClassifier(metric='euclidean',\n",
      "                                                                    n_neighbors=3))])),\n",
      "                             ('model_6',\n",
      "                              RandomForestClassifier(bootstrap=False,\n",
      "                                                     max_depth=50,\n",
      "                                                     min_samples_leaf=2,\n",
      "                                                     min_samples_split=5,\n",
      "                                                     n_estimators=500,\n",
      "                                                     random_state=123))],\n",
      "                 voting='soft')\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Evaluate the best model\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=list(best_combination),\n",
    "    voting=best_voting_scheme\n",
    ")\n",
    "voting_clf.fit(x_train, y_train)\n",
    "y_pred_test = voting_clf.predict(x_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred_test) * 100)\n",
    "print('Recall: ', recall_score(y_test, y_pred_test, average='weighted') * 100)\n",
    "print('Precision: ', precision_score(y_test, y_pred_test, average='weighted') * 100)\n",
    "print('F1-Score: ', f1_score(y_test, y_pred_test, average='weighted') * 100)\n",
    "\n",
    "if best_voting_scheme == 'soft':\n",
    "    # Compute ROC curve and AUC score\n",
    "    y_pred_prob = voting_clf.predict_proba(x_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.title('ROC curve for classifier')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"AUC Score:\", roc_auc_score(y_test, y_pred_prob))\n",
    "\n",
    "# Save the best model\n",
    "joblib_file = \"best_voting_model.pkl\"\n",
    "joblib.dump(voting_clf, joblib_file)\n",
    "\n",
    "# Load and test the saved model\n",
    "loaded_model = joblib.load(joblib_file)\n",
    "print('Loaded model accuracy:', accuracy_score(y_test, loaded_model.predict(x_test)) * 100)\n",
    "print(loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=voting_clf.classes_)\n",
    "cm_display.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
